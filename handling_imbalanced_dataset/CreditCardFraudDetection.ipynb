{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreditCardFraudDetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LsDYJigFA1tu",
        "colab": {}
      },
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_tI4MXy9l_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yi7iv4MTA1t2",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"https://raw.githubusercontent.com/insaid2018/Term-2/master/Data/credit_fraud.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9k2KAwFbA1t8",
        "outputId": "3fc8a37b-309d-4524-d95f-e74d8db90fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0     0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1     0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2     1 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3     1 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4     2 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pG5u12G6A1uJ"
      },
      "source": [
        "## About the Data\n",
        "To quote from Kaggle:\n",
        "\n",
        "\"The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
        "\n",
        "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P7RY2YDLA1uL",
        "outputId": "bdc518af-ed78-4030-8041-f1ffa9d24a70",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "data['Class'].value_counts().plot.bar()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2959a88630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD1CAYAAACyaJl6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7KVbEKVAA1uT",
        "outputId": "7bd72a3d-a1f6-4cc5-f21d-c0cdd2562dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Proportion of the classes in the data:')\n",
        "print(data['Class'].value_counts() / len(data))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportion of the classes in the data:\n",
            "0    0.9962\n",
            "1    0.0038\n",
            "Name: Class, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mEj_b4K5A1ub"
      },
      "source": [
        "We will build a simple logistic regression classifer and compare the results for the classifier without SMOTE to with SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZxAD3Va0A1uc",
        "colab": {}
      },
      "source": [
        "data = data.drop(['Time'], axis = 1)\n",
        "X = np.array(data.loc[:, data.columns != 'Class'])\n",
        "y = np.array(data.loc[:, data.columns == 'Class']).reshape(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ETrCNnWRA1ui",
        "colab": {}
      },
      "source": [
        "# standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "orBcshj5A1un",
        "colab": {}
      },
      "source": [
        "# split into training and testing datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 2, shuffle = True, stratify = y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cWK4Df0WA1us",
        "colab": {}
      },
      "source": [
        "# import logistic regression model and accuracy_score metric\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf = LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YHUexHjoA1u0"
      },
      "source": [
        "# Without SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KAzw0KTVA1u2",
        "colab": {}
      },
      "source": [
        "# fit the model\n",
        "clf.fit(X_train, y_train.ravel())\n",
        "\n",
        "# prediction for training dataset\n",
        "train_pred = clf.predict(X_train)\n",
        "\n",
        "# prediction for testing dataset\n",
        "test_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gQaxjF_PA1u-",
        "outputId": "5a8bef4b-b324-480e-9b13-d07f2ce3585a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Accuracy score for Training Dataset = ', accuracy_score(train_pred, y_train))\n",
        "print('Accuracy score for Testing Dataset = ', accuracy_score(test_pred, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for Training Dataset =  1.0\n",
            "Accuracy score for Testing Dataset =  0.9990909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2F-JK9lrA1vF"
      },
      "source": [
        "Wow! Such high accuracies!\n",
        "\n",
        "You might think that the model has performed exceptionally well. Well, that's not the case. Let us examine the confusion matrix for our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VtpuOTeeA1vG",
        "outputId": "7d8b6fb9-4430-47cf-b071-15fb8b4168bf",
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Training Dataset')\n",
        "print(pd.crosstab(y_train.ravel(), train_pred, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Training Dataset\n",
            "Predicted     0   1   All\n",
            "True                     \n",
            "0          6675   0  6675\n",
            "1             0  25    25\n",
            "All        6675  25  6700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6OpP0-GwA1vO"
      },
      "source": [
        "Now let's interpret the results. \n",
        "\n",
        "134 out of 330 instances which belong to class 1 have been classifed as class 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vkkZnbI0A1vP",
        "outputId": "5043c91c-d144-4025-f4f7-e1ad51e17b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "134/330"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40606060606060607"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rIf2Y-eAA1vW"
      },
      "source": [
        "That is a whopping 41%! We are classifying 41% of the <b>fraud</b> cases as <b>not fraud</b>. This is going to cost some serious losses to the credit card company. You can observe this similarly in the confusion matrix of the Testing Dataset.\n",
        "\n",
        "The higher accuracy is not due to correct classification. The model has predicted the majority class for almost all the examples. And since about 99.8% of the examples actually belong to this class, it leads to such high accuracy scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pK7xr71GA1vX",
        "outputId": "3f6b9ad7-f53d-4c5c-a524-e4dfab057645",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Testing Dataset')\n",
        "print(pd.crosstab(y_test.ravel(), test_pred.ravel(), rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Testing Dataset\n",
            "Predicted     0   1   All\n",
            "True                     \n",
            "0          3287   0  3287\n",
            "1             3  10    13\n",
            "All        3290  10  3300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xi40QKODA1vf"
      },
      "source": [
        "55 out of 162 instances which belong to class 1 have been classifed as class 0. We are missing about 34% of the fraud cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DoXu_oieA1vh"
      },
      "source": [
        "# Using SMOTE\n",
        "Researchers have found that balancing the data will to better classification models. We will try balancing our data using SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1dQv2v89l_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install -q imblearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kuRQlEN7A1vi",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 33)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oYd1CvrtA1vq",
        "colab": {}
      },
      "source": [
        "X_train_new, y_train_new = sm.fit_sample(X_train, y_train.ravel())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "puhGbwHDA1v3",
        "outputId": "0e5365e9-cfcc-4c02-9e04-1b5249a9ddf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# observe that data has been balanced\n",
        "pd.Series(y_train_new).value_counts().plot.bar()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f29567fde10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHTH0Jakjhr4kdcTQl6SO/D/epGOE4bH6jAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bc6FdOh_A1wB",
        "colab": {}
      },
      "source": [
        "# fit the model\n",
        "clf.fit(X_train_new, y_train_new)\n",
        "\n",
        "# prediction for Training data\n",
        "train_pred_sm = clf.predict(X_train_new)\n",
        "\n",
        "# prediction for Testing data\n",
        "test_pred_sm = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lX2nDmxCA1wH",
        "outputId": "b8db2e94-6190-4966-d660-80ca23c9c5f4",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Accuracy score for Training Dataset = ', accuracy_score(train_pred_sm, y_train_new))\n",
        "print('Accuracy score for Testing Dataset = ', accuracy_score(test_pred_sm, y_test))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for Training Dataset =  1.0\n",
            "Accuracy score for Testing Dataset =  0.9990909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5x5b7DXKA1wP"
      },
      "source": [
        "Our accuracy has reduced. But our model has definitely improved. Observe the confusion matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "psjNVX2mA1wY",
        "outputId": "39cb1060-4d3d-4443-e7fc-5eddce3539fa",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Training Dataset')\n",
        "print(pd.crosstab(y_train_new, train_pred_sm, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Training Dataset\n",
            "Predicted     0     1    All\n",
            "True                        \n",
            "0          6675     0   6675\n",
            "1             0  6675   6675\n",
            "All        6675  6675  13350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BsE0umreA1we",
        "outputId": "1992654a-78af-4df5-9508-938abbe76016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "16685/190490"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08758989973226941"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XrIY1nC0A1wk"
      },
      "source": [
        "16685 out of 190490 <b>fraud</b> cases have been classified as <b>not fraud</b>. This is a mere 8.7% compared to the previous 41%.\n",
        "\n",
        "A vast improvement!\n",
        "\n",
        "Same is the case with the Testing Dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Wl9C6vOA1wl",
        "outputId": "b8dd7da2-f700-4466-e9ce-40746505fb88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('Confusion Matrix - Testing Dataset')\n",
        "print(pd.crosstab(y_test.ravel(), test_pred_sm, rownames = ['True'], colnames = ['Predicted'], margins = True))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix - Testing Dataset\n",
            "Predicted     0   1   All\n",
            "True                     \n",
            "0          3287   0  3287\n",
            "1             3  10    13\n",
            "All        3290  10  3300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ol1wZAJ4A1ws",
        "outputId": "65aa2fc1-fd3e-4e66-c425-5e22d6b81ca2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "12/162"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07407407407407407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7fzpuvPZA1wy"
      },
      "source": [
        "Roughly 7.4% of the fraud classes have been classified as not fraud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fUwoquLEA1w0"
      },
      "source": [
        "# Conclusion\n",
        "One might argue that the reduced accuracy is an indicator of lower model performance. However, this is not true.\n",
        "\n",
        "Error in prediction can be made in two ways:\n",
        "1. Classifying <b>not fraud</b> as <b>fraud</b>\n",
        "2. Classifying <b>fraud</b> as <b>not fraud</b>\n",
        "\n",
        "It should not be hard to understand that the second error is costlier than the first.\n",
        "\n",
        "The objective of each classification problem is different. So make sure to evaluate each model with respect to its own objective instead of merely judging it on its accuracy."
      ]
    }
  ]
}