{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install a package command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install <package_name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis packages\n",
    "import pandas as pd\n",
    "import pandas_profiling \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Data Visualization packages\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Other useful packages\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from subprocess import check_output\n",
    "from pydotplus.graphviz import graph_from_dot_data\n",
    "\n",
    "# Sklearn API\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "# Classification Algo Metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "# Regression Algo Metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Stats API\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.max_rows', 500) # OR pd.options.display.max_rows = 500\n",
    "pd.set_option('display.max_columns', 500) # OR pd.options.display.max_columns = 500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OS package commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Statistics', 'ExpediaGroupDataScienceAcademy', 'gitrepos', 'UdemyCourses', '.DS_Store', 'PythonandS3', 'Tableau', 'NaturalLanguageProcessing', 'Computer Vision', 'Python', 'Data Visualization', 'R', 'Fee Receipt', 'MachineLearning', 'Numpy', 'EDA Project', 'PythonandStatistics', 'PyCharmProjects', 'INSAIDGCDProgramSyllabus', 'YoutubeVideos', 'AboutDataScience', 'Useful EDA commands.ipynb', 'WebScrappingScript', 'PythonForFinance', 'PythonDSPresentations', '.ipynb_checkpoints', 'PythonPractice', 'Deep Learning', 'Assignments - Numpy and Pandas', 'ODSCMeetup', 'Data', 'PythonandSparkforBigData', 'Pandas', 'AnalyticsLab', 'Career Guide']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/Users/rajkgupta/DATASCIENCE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(),cbar=False,yticklabels=False,cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(df.corr(),cmap='Blues',annot=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat Map with annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quality correlation matrix\n",
    "k = 12 #number of variables for heatmap\n",
    "cols = df.corr().nlargest(k, 'quality')['quality'].index\n",
    "cm = df[cols].corr()\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cm, annot=True, cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Check Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df.columns.values\n",
    "number_of_columns=12\n",
    "number_of_rows = len(l)-1/number_of_columns\n",
    "plt.figure(figsize=(number_of_columns,5*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.set_style('whitegrid')\n",
    "    sns.boxplot(df[l[i]],color='green',orient='v')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To check distribution-Skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2*number_of_columns,5*number_of_rows))\n",
    "for i in range(0,len(l)):\n",
    "    plt.subplot(number_of_rows + 1,number_of_columns,i+1)\n",
    "    sns.distplot(df[l[i]],kde=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Apply for showing progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook().pandas()\n",
    "movies.progress_apply(lambda x: calculcateNewRating(x['Genre'],x['Rating']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create UDF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data audit Report for continuous variables\n",
    "def continuous_var_summary(x):\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),  \n",
    "                      x.std(), x.var(), x.min(), x.quantile(0.01), x.quantile(0.05),\n",
    "                          x.quantile(0.10),x.quantile(0.25),x.quantile(0.50),x.quantile(0.75), \n",
    "                              x.quantile(0.90),x.quantile(0.95), x.quantile(0.99),x.max()], \n",
    "                  index = ['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR', 'MIN', 'P1', \n",
    "                               'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,'MAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data audit Report for categorical variables\n",
    "def categorical_var_summary(x):\n",
    "    Mode = x.value_counts().sort_values(ascending = False)[0:1].reset_index()\n",
    "    return pd.Series([x.count(), x.isnull().sum(), Mode.iloc[0, 0], Mode.iloc[0, 1], \n",
    "                          round(Mode.iloc[0, 1] * 100/x.count(), 2)], \n",
    "                  index = ['N', 'NMISS', 'MODE', 'FREQ', 'PERCENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value imputation for categorical and continuous variables\n",
    "def missing_imputation(x, stats = 'mean'):\n",
    "    if (x.dtypes == 'float64') | (x.dtypes == 'int64'):\n",
    "        x = x.fillna(x.mean()) if stats == 'mean' else x.fillna(x.median())\n",
    "    else:\n",
    "        x = x.fillna(x.mode())\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An utility function to create dummy variable\n",
    "def create_dummies(df, colname):\n",
    "    col_dummies = pd.get_dummies(df[colname], prefix = colname, drop_first = True)\n",
    "    df = pd.concat([df, col_dummies], axis = 1)\n",
    "    df.drop(colname, axis = 1, inplace = True )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pandas_profiling.ProfileReport(cars)\n",
    "report.to_file(output_file = 'profilereport.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sepearate categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate categorical and continuous variables\n",
    "cars_conti_vars = cars.loc[:, (cars.dtypes == 'float64') | (cars.dtypes == 'int64')]\n",
    "cars_cat_vars = cars.loc[:, (cars.dtypes == 'object')]\n",
    "\n",
    "# Simper way of doing:\n",
    "# cars_conti_vars = cars.select_dtypes(include = ['float64', 'int64'])\n",
    "# car_sales_cat = cars.select_dtypes(include = ['object'])\n",
    "cars_conti_vars.apply(continuous_var_summary).T.round(1)\n",
    "cars_cat_vars.apply(categorical_var_summary).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outlier treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_conti_vars = cars_conti_vars.apply(lambda x: x.clip(lower = x.dropna().quantile(0.01), \n",
    "                                                         upper = x.quantile(0.99)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# missing value treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_conti_vars = cars_conti_vars.apply(missing_imputation)\n",
    "cars_cat_vars = cars_cat_vars.apply(missing_imputation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
